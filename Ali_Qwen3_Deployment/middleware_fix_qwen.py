import os
import json
import re
import uvicorn
import httpx
import time
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse

# ================= ç”¨æˆ·é…ç½®åŒºåŸŸ =================
# æ‚¨çš„ vLLM æœåŠ¡åœ°å€
VLLM_API_BASE = "http://localhost:8001/v1"

# ä¸­é—´ä»¶ç›‘å¬ç«¯å£
PORT = 4000

# æ‚¨çš„è‡ªå®šä¹‰æ¨¡å‹åç§° (åœ¨è¿™é‡Œå†™æ­»)
TARGET_MODEL_NAME = "Qwen/Qwen3-235B-A22B-Instruct" 

# vLLM çš„ API Key (åœ¨è¿™é‡Œå†™æ­»)
VLLM_API_KEY = "empty"

# ä¸Šä¸‹æ–‡é™åˆ¶ (80k)
MAX_CONTEXT_TOKENS = 80000 
# ===========================================

app = FastAPI()
# trust_env=False: ç¦æ­¢è¯»å–ç³»ç»Ÿä»£ç†ç¯å¢ƒå˜é‡ (HTTP_PROXY ç­‰)ï¼Œç¡®ä¿è¯·æ±‚ç›´æ¥å‘é€ç»™å±€åŸŸç½‘/æœ¬åœ° vLLM
client = httpx.AsyncClient(timeout=600.0, trust_env=False)

def estimate_tokens(text):
    return len(text) // 3

def parse_hermes_xml(content):
    """å°è¯•ä»æ–‡æœ¬ä¸­æå– Hermes é£æ ¼çš„ <tool_code> XML"""
    tool_calls = []
    pattern = r"<tool_code>\s*(.*?)\s*</tool_code>"
    matches = re.findall(pattern, content, re.DOTALL)
    
    for i, code_str in enumerate(matches):
        try:
            clean_json = re.sub(r"^```json\s*|\s*```$", "", code_str.strip(), flags=re.IGNORECASE)
            tool_call_data = json.loads(clean_json)
            tool_calls.append({
                "id": f"call_{i}_{os.urandom(4).hex()}",
                "type": "function",
                "function": {
                    "name": tool_call_data.get("name"),
                    "arguments": json.dumps(tool_call_data.get("arguments", {}))
                }
            })
        except json.JSONDecodeError:
            print(f"âš ï¸ è§£æå·¥å…·è°ƒç”¨ JSON å¤±è´¥: {code_str}")
            continue
    return tool_calls

def convert_claude_messages_to_openai(claude_body):
    """å°† Claude æ ¼å¼çš„ messages è¯·æ±‚è½¬æ¢ä¸º OpenAI æ ¼å¼"""
    openai_messages = []
    
    # 1. å¤„ç† system prompt
    # æˆ‘ä»¬ç¨åä¼šåœ¨è¿™é‡Œæ³¨å…¥å·¥å…·å®šä¹‰ï¼Œæ‰€ä»¥è¿™é‡Œåªæå–åŸå§‹ system
    system_content = claude_body.get("system", "")
    if system_content:
        openai_messages.append({
            "role": "system",
            "content": system_content
        })
        
    # 2. å¤„ç† messages åˆ—è¡¨
    for msg in claude_body.get("messages", []):
        role = msg["role"]
        content = msg["content"]
        
        # Claude çš„ content å¯èƒ½æ˜¯åˆ—è¡¨ï¼ˆåŒ…å« text æˆ– imageï¼‰
        if isinstance(content, list):
            new_content = ""
            for part in content:
                if part.get("type") == "text":
                    new_content += part.get("text", "")
                # æš‚æ—¶å¿½ç•¥ image
            
            openai_messages.append({"role": role, "content": new_content})
        else:
            openai_messages.append({"role": role, "content": content})
            
    # 3. å¤„ç† tools
    # æ³¨æ„ï¼šæˆ‘ä»¬ä¸å†è¿”å› tools åˆ—è¡¨ç»™ vLLM APIï¼Œè€Œæ˜¯è¿”å› raw_tools ç”¨äºç”Ÿæˆ System Prompt
    raw_tools = []
    if "tools" in claude_body:
        for tool in claude_body["tools"]:
            raw_tools.append({
                "name": tool["name"],
                "description": tool.get("description", ""),
                "parameters": tool["input_schema"]
            })
            
    return openai_messages, raw_tools

def generate_tool_system_prompt(tools):
    """ç”Ÿæˆ Hermes/Qwen é£æ ¼çš„å·¥å…·å®šä¹‰ Prompt"""
    tools_json = json.dumps(tools, indent=2)
    prompt = f"""
You have access to the following tools:
<tools>
{tools_json}
</tools>

When you need to call a tool, please output the tool call inside <tool_code> tags.
The format should be a JSON object with "name" and "arguments" keys.
Example:
<tool_code>
{{"name": "get_weather", "arguments": {{"location": "Beijing"}}}}
</tool_code>
"""
    return prompt

def convert_openai_response_to_claude(openai_resp):
    """å°† OpenAI æ ¼å¼çš„å“åº”è½¬æ¢ä¸º Claude æ ¼å¼"""
    choice = openai_resp["choices"][0]
    message = choice["message"]
    
    claude_content = []
    stop_reason = "end_turn"
    
    # 1. å¤„ç†æ–‡æœ¬å†…å®¹
    if message.get("content"):
        claude_content.append({
            "type": "text",
            "text": message["content"]
        })
        
    # 2. å¤„ç†å·¥å…·è°ƒç”¨
    if message.get("tool_calls"):
        stop_reason = "tool_use"
        for tool_call in message["tool_calls"]:
            claude_content.append({
                "type": "tool_use",
                "id": tool_call["id"],
                "name": tool_call["function"]["name"],
                "input": json.loads(tool_call["function"]["arguments"])
            })
            
    return {
        "id": openai_resp["id"],
        "type": "message",
        "role": "assistant",
        "content": claude_content,
        "model": TARGET_MODEL_NAME,
        "stop_reason": stop_reason,
        "stop_sequence": None,
        "usage": {
            "input_tokens": openai_resp["usage"]["prompt_tokens"],
            "output_tokens": openai_resp["usage"]["completion_tokens"]
        }
    }

# æ‹¦æˆª Claude çš„æ ¸å¿ƒè·¯ç”±
@app.post("/v1/messages")
@app.post("/messages")
async def proxy_claude_messages(request: Request):
    try:
        body = await request.json()
        print("ğŸ“¨ æ”¶åˆ° Claude åè®®è¯·æ±‚ (/v1/messages)")
        
        # 1. ä¼°ç®— Token (80k ä¿æŠ¤)
        total_chars = 0
        if "system" in body:
             total_chars += len(body["system"])
        for msg in body.get("messages", []):
            if isinstance(msg["content"], str):
                total_chars += len(msg["content"])
        
        if (total_chars // 3) > MAX_CONTEXT_TOKENS:
             return JSONResponse(
                content={
                    "type": "error",
                    "error": {
                        "type": "invalid_request_error",
                        "message": f"Context limit reached! Please run /compact."
                    }
                },
                status_code=400
            )

        # 2. åè®®è½¬æ¢: Claude -> OpenAI
        openai_messages, raw_tools = convert_claude_messages_to_openai(body)
        
        # === æ ¸å¿ƒä¿®æ­£ï¼šå·¥å…· Prompt æ³¨å…¥ ===
        # å¦‚æœæœ‰å·¥å…·ï¼Œæˆ‘ä»¬æ‰‹åŠ¨æŠŠå®ƒä»¬æ³¨å…¥åˆ° System Prompt ä¸­
        # è€Œä¸æ˜¯é€šè¿‡ API çš„ tools å‚æ•°ä¼ é€’ (å› ä¸º vLLM æ²¡é… parser ä¼šæŠ¥é”™)
        if raw_tools:
            tool_prompt = generate_tool_system_prompt(raw_tools)
            
            # æ£€æŸ¥ messages é‡Œæ˜¯å¦å·²ç»æœ‰ system æ¶ˆæ¯
            system_msg_index = -1
            for i, msg in enumerate(openai_messages):
                if msg["role"] == "system":
                    system_msg_index = i
                    break
            
            if system_msg_index >= 0:
                # è¿½åŠ åˆ°ç°æœ‰ system åé¢
                openai_messages[system_msg_index]["content"] += "\n\n" + tool_prompt
            else:
                # æ’å…¥æ–°çš„ system æ¶ˆæ¯åˆ°å¼€å¤´
                openai_messages.insert(0, {
                    "role": "system",
                    "content": tool_prompt
                })
            
            print(f"ğŸ’‰ å·²æ³¨å…¥ {len(raw_tools)} ä¸ªå·¥å…·å®šä¹‰åˆ° System Prompt")

        openai_req = {
            "model": TARGET_MODEL_NAME,
            "messages": openai_messages,
            "max_tokens": body.get("max_tokens", 4096),
            "temperature": body.get("temperature", 0.7),
            "stream": False # å¼ºåˆ¶å…³é—­æµå¼
        }
        
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†è®¾ç½® openai_req["tools"]ï¼Œå®Œå…¨ä¾èµ– Prompt

        # 3. å‘é€ç»™ vLLM (OpenAI æ¥å£)
        print(f"ğŸš€ è½¬å‘ç»™ vLLM (æ¨¡å‹: {TARGET_MODEL_NAME})...")
        response = await client.post(
            f"{VLLM_API_BASE}/chat/completions",
            json=openai_req,
            headers={"Authorization": f"Bearer {VLLM_API_KEY}"},
            timeout=600.0
        )
        
        if response.status_code != 200:
            print(f"âŒ vLLM æŠ¥é”™: {response.text}")
            return JSONResponse(content={"error": "vLLM error"}, status_code=response.status_code)
            
        openai_result = response.json()
        
        # 4. æ£€æŸ¥å¹¶ä¿®å¤ XML å·¥å…·è°ƒç”¨
        choice = openai_result["choices"][0]
        content = choice["message"].get("content", "") or ""
        
        if "<tool_code>" in content:
            print(f"ğŸ› ï¸ æ•è·åˆ° XML å·¥å…·è°ƒç”¨ï¼Œæ­£åœ¨ä¿®å¤...")
            extracted_tools = parse_hermes_xml(content)
            if extracted_tools:
                choice["message"]["tool_calls"] = extracted_tools
                # ä¸æ¸…ç©º contentï¼Œä¿ç•™æ€è€ƒè¿‡ç¨‹
        
        # 5. åè®®è½¬æ¢: OpenAI -> Claude
        claude_response = convert_openai_response_to_claude(openai_result)
        
        print("âœ… å“åº”æˆåŠŸè¿”å›")
        return JSONResponse(content=claude_response)

    except Exception as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: {e}")
        return JSONResponse(content={"error": str(e)}, status_code=500)

if __name__ == "__main__":
    print(f"ğŸš€ Claude åè®®å…¼å®¹å±‚å·²å¯åŠ¨")
    print(f"ğŸ¯ ç›®æ ‡æ¨¡å‹: {TARGET_MODEL_NAME}")
    print(f"ğŸ”‘ API Key: {VLLM_API_KEY}")
    print(f"ğŸ“¡ ç›‘å¬ç«¯å£: {PORT} (è¯·é…ç½® Claude Code Base URL ä¸º http://localhost:{PORT})")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
