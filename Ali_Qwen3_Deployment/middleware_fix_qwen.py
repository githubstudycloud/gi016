import os
import json
import re
import uvicorn
import httpx
import time
import ast
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse

# ================= ç”¨æˆ·é…ç½®åŒºåŸŸ =================
# æ‚¨çš„ vLLM æœåŠ¡åœ°å€
VLLM_API_BASE = "http://localhost:8001/v1"

# ä¸­é—´ä»¶ç›‘å¬ç«¯å£
PORT = 4000

# æ‚¨çš„è‡ªå®šä¹‰æ¨¡å‹åç§° (åœ¨è¿™é‡Œå†™æ­»)
TARGET_MODEL_NAME = "Qwen/Qwen3-235B-A22B-Instruct" 

# vLLM çš„ API Key (åœ¨è¿™é‡Œå†™æ­»)
VLLM_API_KEY = "empty"

# ä¸Šä¸‹æ–‡é™åˆ¶ (80k)
MAX_CONTEXT_TOKENS = 80000 
# ===========================================

app = FastAPI()
# trust_env=False: ç¦æ­¢è¯»å–ç³»ç»Ÿä»£ç†ç¯å¢ƒå˜é‡ (HTTP_PROXY ç­‰)ï¼Œç¡®ä¿è¯·æ±‚ç›´æ¥å‘é€ç»™å±€åŸŸç½‘/æœ¬åœ° vLLM
client = httpx.AsyncClient(timeout=600.0, trust_env=False)

def estimate_tokens(text):
    return len(text) // 3

def parse_hermes_xml(content):
    """å°è¯•ä»æ–‡æœ¬ä¸­æå– Hermes é£æ ¼çš„ <tool_code> æˆ– Qwen é£æ ¼çš„ <tool_call> XML"""
    tool_calls = []
    
    # 1. ç»Ÿä¸€æ ‡ç­¾: å°† <tool_call> æ›¿æ¢ä¸º <tool_code> ä»¥ä¾¿ç»Ÿä¸€å¤„ç†ï¼Œæˆ–è€…æ”¯æŒä¸¤ç§
    # æˆ‘ä»¬æ”¯æŒä¸¤ç§æ ‡ç­¾ï¼štool_code (Hermes) å’Œ tool_call (Qwen)
    
    # åŒ¹é…æ¨¡å¼ï¼šæ”¯æŒ tool_code æˆ– tool_call
    # Group 1: æ ‡ç­¾å (tool_code|tool_call)
    # Group 2: å†…å®¹
    pattern = r"<(tool_code|tool_call)>\s*(?:```json)?\s*(.*?)\s*(?:```)?\s*</\1>"
    matches = re.findall(pattern, content, re.DOTALL | re.IGNORECASE)
    
    if not matches:
        # å¤‡ç”¨ï¼šå°è¯•åŒ¹é…æœªé—­åˆçš„æ ‡ç­¾
        pattern_lazy = r"<(tool_code|tool_call)>\s*(?:```json)?\s*(.*?)\s*(?:```)?\s*$"
        matches = re.findall(pattern_lazy, content, re.DOTALL | re.IGNORECASE)

    for i, (tag_name, code_str) in enumerate(matches):
        print(f"ğŸ” å°è¯•è§£æå·¥å…·å†…å®¹ç‰‡æ®µ (Tag: {tag_name}): {code_str[:100]}...")
        
        try:
            # æ¸…æ´—å¯èƒ½æ®‹ç•™çš„ markdown æ ‡è®°
            clean_json = code_str.strip()
            clean_json = re.sub(r"^```(?:json)?\s*", "", clean_json, flags=re.IGNORECASE)
            clean_json = re.sub(r"\s*```$", "", clean_json)
            clean_json = clean_json.strip()
            
            if not clean_json: 
                print("âš ï¸ å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
                continue

            tool_call_data = None
            
            # ç­–ç•¥1: ç›´æ¥ JSON è§£æ
            try:
                tool_call_data = json.loads(clean_json)
            except json.JSONDecodeError:
                # ç­–ç•¥2: å°è¯• Python AST è§£æ (å®¹å¿å•å¼•å·)
                try:
                    tool_call_data = ast.literal_eval(clean_json)
                except:
                    pass
            
            # ç­–ç•¥3: å¦‚æœå†…å®¹åŒ…å«é¢å¤–æ–‡æœ¬ï¼Œå°è¯•æå–ç¬¬ä¸€ä¸ª {...} å—
            if tool_call_data is None:
                json_match = re.search(r"(\{.*\})", clean_json, re.DOTALL)
                if json_match:
                    potential_json = json_match.group(1)
                    try:
                        tool_call_data = json.loads(potential_json)
                    except:
                        try:
                            tool_call_data = ast.literal_eval(potential_json)
                        except:
                            pass
            
            if tool_call_data is None:
                print(f"âš ï¸ æ— æ³•è§£æä¸º JSON æˆ– Python Dict: {clean_json}")
                continue
            
            # éªŒè¯å¿…è¦å­—æ®µ
            if "name" not in tool_call_data:
                print(f"âš ï¸ å·¥å…·è°ƒç”¨ç¼ºå°‘ name å­—æ®µ: {clean_json}")
                continue
                
            arguments = tool_call_data.get("arguments", {})
            if isinstance(arguments, dict):
                arguments = json.dumps(arguments)
            
            tool_calls.append({
                "id": f"call_{i}_{os.urandom(4).hex()}",
                "type": "function",
                "function": {
                    "name": tool_call_data.get("name"),
                    "arguments": arguments
                }
            })
        except Exception as e:
            print(f"âš ï¸ è§£æå·¥å…·è°ƒç”¨å‘ç”Ÿå¼‚å¸¸: {e}\nåŸå§‹å†…å®¹: {code_str}")
            continue
            
    return tool_calls

def convert_claude_messages_to_openai(claude_body):
    """
    å°† Claude æ ¼å¼çš„ messages è¯·æ±‚è½¬æ¢ä¸º OpenAI æ ¼å¼
    åŒæ—¶å¤„ç†å†å²è®°å½•ä¸­çš„ tool_use å’Œ tool_resultï¼Œå°†å…¶è½¬æ¢ä¸º Hermes XML æ ¼å¼
    """
    openai_messages = []
    
    # 1. å¤„ç† system prompt
    system_content = claude_body.get("system", "")
    if system_content:
        openai_messages.append({
            "role": "system",
            "content": system_content
        })
        
    # 2. å¤„ç† messages åˆ—è¡¨
    for msg in claude_body.get("messages", []):
        role = msg["role"]
        content = msg["content"]
        
        text_parts = []
        
        # Claude çš„ content å¯èƒ½æ˜¯åˆ—è¡¨ï¼ˆåŒ…å« text, tool_use, tool_resultï¼‰
        if isinstance(content, list):
            for part in content:
                part_type = part.get("type")
                
                if part_type == "text":
                    text_parts.append(part.get("text", ""))
                    
                elif part_type == "tool_use":
                    # å°† Claude çš„å·¥å…·è°ƒç”¨è½¬æ¢ä¸º Hermes çš„ <tool_code>
                    args_json = json.dumps(part.get("input", {}))
                    tool_xml = f"\n<tool_code>\n{{\"name\": \"{part['name']}\", \"arguments\": {args_json}}}\n</tool_code>"
                    text_parts.append(tool_xml)
                    
                elif part_type == "tool_result":
                    # å°† Claude çš„å·¥å…·ç»“æœè½¬æ¢ä¸º Hermes çš„ <tool_output>
                    res_content = part.get("content", "")
                    res_text = ""
                    if isinstance(res_content, str):
                        res_text = res_content
                    elif isinstance(res_content, list):
                        for sub in res_content:
                            if sub.get("type") == "text":
                                res_text += sub.get("text", "")
                    
                    # ç®€åŒ– outputï¼Œé˜²æ­¢è¿‡é•¿
                    tool_output_xml = f"\n<tool_output>\n{res_text}\n</tool_output>"
                    text_parts.append(tool_output_xml)
                    
        elif isinstance(content, str):
            text_parts.append(content)
            
        final_content = "".join(text_parts)
        openai_messages.append({"role": role, "content": final_content})
            
    # 3. å¤„ç† tools (æå–å®šä¹‰ç”¨äºæ³¨å…¥ System Prompt)
    raw_tools = []
    if "tools" in claude_body:
        for tool in claude_body["tools"]:
            raw_tools.append({
                "name": tool["name"],
                "description": tool.get("description", ""),
                "parameters": tool["input_schema"]
            })
            
    return openai_messages, raw_tools

def generate_tool_system_prompt(tools):
    """ç”Ÿæˆ Qwen 2.5/3 å®˜æ–¹æ¨èçš„å·¥å…·å®šä¹‰ Prompt"""
    
    # 1. è½¬æ¢ä¸º OpenAI æ ‡å‡†æ ¼å¼ (type: function)
    openai_tools = []
    for tool in tools:
        openai_tools.append({
            "type": "function",
            "function": {
                "name": tool["name"],
                "description": tool["description"],
                "parameters": tool["parameters"]
            }
        })
    
    tools_json = json.dumps(openai_tools, indent=None) # Compact JSON
    
    prompt = f"""# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{tools_json}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{{"name": <function-name>, "arguments": <args-json-object>}}
</tool_call>
"""
    return prompt

def convert_openai_response_to_claude(openai_resp):
    """å°† OpenAI æ ¼å¼çš„å“åº”è½¬æ¢ä¸º Claude æ ¼å¼"""
    choice = openai_resp["choices"][0]
    message = choice["message"]
    
    claude_content = []
    stop_reason = "end_turn"
    
    # 1. å¤„ç†æ–‡æœ¬å†…å®¹
    raw_content = message.get("content", "")
    
    # å°è¯•ç§»é™¤ raw_content ä¸­çš„ <tool_code> æˆ– <tool_call> éƒ¨åˆ†ï¼Œåªä¿ç•™æ€è€ƒæ–‡æœ¬
    display_text = re.sub(r"<(tool_code|tool_call)>.*?</\1>", "", raw_content, flags=re.DOTALL).strip()
    # è¿˜è¦ç§»é™¤å¯èƒ½çš„æ®‹ç•™é—­åˆæ ‡ç­¾
    display_text = re.sub(r"</(tool_code|tool_call)>", "", display_text).strip()
    
    if display_text:
        claude_content.append({
            "type": "text",
            "text": display_text
        })
        
    # 2. å¤„ç†å·¥å…·è°ƒç”¨
    if message.get("tool_calls"):
        stop_reason = "tool_use"
        for tool_call in message["tool_calls"]:
            claude_content.append({
                "type": "tool_use",
                "id": tool_call["id"],
                "name": tool_call["function"]["name"],
                "input": json.loads(tool_call["function"]["arguments"])
            })
            
    return {
        "id": openai_resp["id"],
        "type": "message",
        "role": "assistant",
        "content": claude_content,
        "model": TARGET_MODEL_NAME,
        "stop_reason": stop_reason,
        "stop_sequence": None,
        "usage": {
            "input_tokens": openai_resp["usage"]["prompt_tokens"],
            "output_tokens": openai_resp["usage"]["completion_tokens"]
        }
    }

@app.post("/v1/messages")
@app.post("/messages")
async def proxy_claude_messages(request: Request):
    try:
        body = await request.json()
        print("\nğŸ“¨ [Claude Request] æ”¶åˆ° /v1/messages è¯·æ±‚")
        
        # 1. ä¼°ç®— Token (80k ä¿æŠ¤)
        total_chars = 0
        if "system" in body:
             total_chars += len(body["system"])
        for msg in body.get("messages", []):
            content = msg.get("content", "")
            if isinstance(content, str):
                total_chars += len(content)
        
        if (total_chars // 3) > MAX_CONTEXT_TOKENS:
             return JSONResponse(
                content={
                    "type": "error",
                    "error": {
                        "type": "invalid_request_error",
                        "message": f"Context limit reached! Please run /compact."
                    }
                },
                status_code=400
            )

        # 2. åè®®è½¬æ¢: Claude -> OpenAI
        openai_messages, raw_tools = convert_claude_messages_to_openai(body)
        
        # === æ ¸å¿ƒä¿®æ­£ï¼šå·¥å…· Prompt æ³¨å…¥ ===
        stop_tokens = [] # åŠ¨æ€åœæ­¢è¯
        
        if raw_tools:
            tool_prompt = generate_tool_system_prompt(raw_tools)
            stop_tokens = ["</tool_call>", "</tool_code>"] # å‘Šè¯‰æ¨¡å‹å†™å®Œå·¥å…·è°ƒç”¨å°±åœ
            
            # ç­–ç•¥ï¼šå¦‚æœ messages é‡Œæ²¡æœ‰ systemï¼Œå°±æ–°å»ºä¸€ä¸ªã€‚
            # å¦‚æœæœ‰ï¼Œæˆ‘ä»¬åœ¨ User æ¶ˆæ¯é‡Œæ³¨å…¥æé†’ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¿®æ”¹ System Prompt
            # å› ä¸ºé•¿å¯¹è¯ä¸­ System Prompt å®¹æ˜“è¢«é—å¿˜
            
            # A. ç¡®ä¿ System Prompt å­˜åœ¨
            system_msg_index = -1
            for i, msg in enumerate(openai_messages):
                if msg["role"] == "system":
                    system_msg_index = i
                    break
            
            if system_msg_index >= 0:
                # æ›¿æ¢æˆ–è¿½åŠ åˆ°ç°æœ‰ system
                openai_messages[system_msg_index]["content"] += "\n\n" + tool_prompt
            else:
                # æ’å…¥æ–°çš„ system æ¶ˆæ¯åˆ°å¼€å¤´
                openai_messages.insert(0, {
                    "role": "system",
                    "content": tool_prompt
                })
            
            # B. [å…³é”®] åœ¨æœ€åä¸€æ¡ User Message è¿½åŠ å¼ºåŠ›æé†’
            # åªæœ‰å½“ç”¨æˆ·ç¡®å®åœ¨è¯´è¯æ—¶æ‰è¿½åŠ 
            if openai_messages and openai_messages[-1]["role"] == "user":
                reminder = "\n\n(IMPORTANT: If you need to use a tool, output the JSON inside <tool_call> tags immediately. Do not explain.)"
                openai_messages[-1]["content"] += reminder
            
            print(f"ğŸ’‰ å·²æ³¨å…¥ {len(raw_tools)} ä¸ªå·¥å…·å®šä¹‰ (System + User Reminder)")

        # 3. æ„å»ºå‘é€ç»™ vLLM çš„è¯·æ±‚
        openai_req = {
            "model": TARGET_MODEL_NAME,
            "messages": openai_messages,
            "max_tokens": body.get("max_tokens", 4096),
            "temperature": body.get("temperature", 0.7),
            "stream": False,
            "stop": stop_tokens if stop_tokens else None # ä½¿ç”¨ Stop Token é˜²æ­¢åºŸè¯
        }
        
        # ğŸš« åˆ é™¤ API å‚æ•°
        if "tools" in openai_req: del openai_req["tools"]
        if "tool_choice" in openai_req: del openai_req["tool_choice"]

        print(f"ğŸš€ è½¬å‘ç»™ vLLM (ç«¯å£ 8001)...")
        response = await client.post(
            f"{VLLM_API_BASE}/chat/completions",
            json=openai_req,
            headers={"Authorization": f"Bearer {VLLM_API_KEY}"},
            timeout=600.0
        )
        
        if response.status_code != 200:
            print(f"âŒ vLLM æŠ¥é”™ (Status {response.status_code}): {response.text}")
            return JSONResponse(content={"error": f"vLLM Error: {response.text}"}, status_code=response.status_code)
            
        openai_result = response.json()
        
        # === è°ƒè¯•æ—¥å¿— ===
        raw_response_content = openai_result["choices"][0]["message"].get("content", "")
        print(f"ğŸ” [Model Response Preview]: {raw_response_content[:200]}...")
        if "<tool_call>" in raw_response_content or "<tool_code>" in raw_response_content:
            print("âœ¨ æ£€æµ‹åˆ° XML æ ‡è®°ï¼")
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ° XML æ ‡è®° (å¯èƒ½æ˜¯çº¯æ–‡æœ¬å›å¤)")
        # ==============

        # 4. æ£€æŸ¥å¹¶ä¿®å¤ XML å·¥å…·è°ƒç”¨
        choice = openai_result["choices"][0]
        content = choice["message"].get("content", "") or ""
        
        # å¦‚æœå› ä¸º stop token åœæ­¢ï¼Œæˆ‘ä»¬éœ€è¦æŠŠè¢«æˆªæ–­çš„é—­åˆæ ‡ç­¾è¡¥å›æ¥ä»¥ä¾¿æ­£åˆ™åŒ¹é…
        if openai_result["choices"][0].get("finish_reason") == "stop":
             # æ£€æŸ¥æ˜¯å¦ä»¥æœªé—­åˆçš„æ ‡ç­¾ç»“å°¾
             if "<tool_call>" in content and "</tool_call>" not in content:
                 content += "</tool_call>"
             elif "<tool_code>" in content and "</tool_code>" not in content:
                 content += "</tool_code>"
        
        if "<tool_call>" in content or "<tool_code>" in content:
            print(f"ğŸ› ï¸ æ­£åœ¨è§£æ XML å·¥å…·è°ƒç”¨...")
            extracted_tools = parse_hermes_xml(content)
            if extracted_tools:
                print(f"âœ… è§£ææˆåŠŸ: {len(extracted_tools)} ä¸ªå·¥å…·")
                choice["message"]["tool_calls"] = extracted_tools
            else:
                print(f"âŒ è§£æå¤±è´¥: æ‰¾åˆ°äº†æ ‡ç­¾ä½†æ— æ³•æå– JSON")
        
        # 5. åè®®è½¬æ¢: OpenAI -> Claude
        claude_response = convert_openai_response_to_claude(openai_result)
        
        return JSONResponse(content=claude_response)

    except Exception as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: {e}")
        return JSONResponse(content={"error": str(e)}, status_code=500)

if __name__ == "__main__":
    print(f"ğŸš€ Claude åè®®å…¼å®¹å±‚å·²å¯åŠ¨ (vLLM 400 ä¿®å¤ç‰ˆ + å¢å¼ºè°ƒè¯•)")
    print(f"ğŸ¯ ç›®æ ‡æ¨¡å‹: {TARGET_MODEL_NAME}")
    print(f"ğŸ”‘ API Key: {VLLM_API_KEY}")
    print(f"ğŸ“¡ ç›‘å¬ç«¯å£: {PORT}")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
